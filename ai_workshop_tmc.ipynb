{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41ce62a8-251f-4f9e-b375-e93a5861c3fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Part II</br>Building the AI Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4a4c19-69f0-45ff-93fd-18bc96358d94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474e9bdb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* [Attention Is All You Need](https://arxiv.org/pdf/1706.03762) Vaswani et al. (2017, Google Brain/ Research)\n",
    "* 5 days to 1 million users (OpenAI)\n",
    "* 1.8 billion monthly visits in March 2023 (OpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7cd24b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Agricultural Revolution**: Around 10,000 BCE, shift to settled farming.\n",
    "- **Industrial Revolution**: Late 18th century, rise of industrialization.\n",
    "- **Digital (Computer) Revolution**: Mid-20th century, advent of computers.\n",
    "- **AI Revolution**: Early 21st century, integration of artificial intelligence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f52aeb-e03e-445e-898f-50995dd79148",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Agenda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae92ca-3e92-4b2f-8b78-10130d41749e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Introduction to LLMs\n",
    "* Starting Docker Containers\n",
    "* Build AI Assistant (Walkthrough & HandsOn)\n",
    "    * Ingestion (Load, Split, Embed, Store)\n",
    "    * Similarity Search\n",
    "    * Combine Context\n",
    "    * Response Generation\n",
    "* Langserve and Streamlit App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192fd6c0-9607-4a12-bccd-f8183153597b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* We will build a simple retrieval augmented generation (RAG) pipeline and complete HandsOn tasks.\n",
    "* The notebook is based on [langchains rag intro](https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_1_to_4.ipynb).\n",
    "* We build towards a broader understanding of the RAG langscape langchain's [rag from scratch](https://github.com/langchain-ai/rag-from-scratch/tree/main)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e2cb58-bb54-4629-a0c9-4e1afe38140b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812f0d9-1fc8-43ba-b72a-5989710ff4f0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Complete Installation and Understand Functioning of Essential Tools  \n",
    "2. **Understand the Basics of Large Language Models (LLMs)**\n",
    "3. **Understand on a Programmatic Level how AI Assistants are Built**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a836d5ad-e281-4977-8ca7-285fbe1ce20d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Starting Docker Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4064f738-58cc-4365-9800-11a3803f54af",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```bash\n",
    "docker-compose -up -d --build\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab14572-84d8-4e92-a999-2f5cabfe9d32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction to LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1fe82f-a383-4f2a-b68d-1ad408d866bd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Slides are shamelessly taken from 3Blue1Brown's [But what is a GPT? Visual intro to transformers | Chapter 5, Deep Learning](https://www.youtube.com/watch?v=wjZofJX0v4M&ab_channel=3Blue1Brown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b109fa-ec86-42bc-a09a-ac5b79148a5d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![/overview.jpeg](assets/imgs/overview.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ffd28-4838-48d7-bc8c-b5e671b90d1d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![/tokens.jpeg](assets/imgs/tokens.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df524967-2689-49da-b785-545a0abc524a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![/giving_meaning.jpeg](assets/imgs/giving_meaning.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780faa85-325c-45ce-a1a6-2185b16a61b8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Build AI Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7374b2-ce57-4511-be6a-e5130984c9e8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![assets/imgs/simple_rag.png](assets/imgs/simple_rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963535df",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- **Ingestion**: Load and preprocess documents for further processing.\n",
    "    - **Load**: Upload documents to the backend.\n",
    "    - **Split**: Split documents into manageable chunks using characters, sections, semantic meaning, and delimiters.\n",
    "    - **Embed**: Convert document chunks (and query) into vector embeddings for representation.\n",
    "    - **Store**: Store the embeddings in a vector database (Vectorstore) for efficient retrieval.\n",
    "- **Similarity Search**: Use the query embedding to search and retrieve the most relevant document chunks from the Vectorstore.\n",
    "- **Combine Context**: Combine retrieved document chunks with the query to provide context for the generation model.\n",
    "- **Response Generation**: Use a language model to generate a response based on the query and retrieved context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4434f741",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e832b105-edf7-4160-9e76-ac5d351337fb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Keep it Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f871a327-6b29-4a71-ba29-5cb4392b0fff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The following is only to suppress output which we do not care about in this workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219cb0fc-1209-4ae5-ba7e-2b3b31119aa2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Setting USER_AGENT variable for jupyter notebook\n",
    "os.environ['USER_AGENT'] = 'jovyan'\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Disable info messages\n",
    "logging.getLogger().setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5870cf7-2b9f-412a-aadc-2c9fbecf895e",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### #REMOVE Package Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "3a88555a-53a5-4ab8-ba3d-e6dd3a26c71a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eb312d-8a07-4df3-8462-72ac526715f7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "df28175e-24b6-4939-8a3c-5a1f9511f51e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import bs4  # Library for web scraping and parsing HTML/XML\n",
    "from langchain import hub  # Access langchain hub for pre-built tools and models\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Tool to split text recursively by characters\n",
    "from langchain_core.output_parsers import StrOutputParser  # Parses output into strings\n",
    "from langchain_core.runnables import RunnablePassthrough  # Pass-through runnable for data processing\n",
    "from langchain_community.chat_models import ChatOllama  # Chat model from Langchain Community\n",
    "from langchain_community.embeddings.ollama import OllamaEmbeddings  # Ollama embeddings for text representation\n",
    "from langchain_community.document_loaders import WebBaseLoader  # Load documents from the web\n",
    "from langchain_community.vectorstores import Chroma  # Chroma vector store for efficient retrieval\n",
    "from langchain_community.document_loaders import PyPDFLoader # reading in pdfs\n",
    "from langchain.prompts import ChatPromptTemplate # class for promts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3cb8c7-eb50-4a78-a199-e35ee99f70c2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21a5073d-13dc-4efd-a678-844268160afa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "OLLAMA_LARGE_LANGUAGE_MODEL = \"wizardlm2:7b\"  # Specifies the large language model version\n",
    "OLLAMA_SERVER = \"http://ollama:11434\"  # URL for the Ollama server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9a0a964e-d7d5-46f3-bc88-645023b6a615",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "question = \"What is the TMC Entrepreneurial Lab?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cae3a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492978da-2e2b-4e99-a399-754e17092e29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952dd1ab-246a-4962-a34a-94ac01ae08eb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[Document Loaders](https://python.langchain.com/docs/integrations/document_loaders/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a72179-477a-4769-b161-563b01ffc6a6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "071aa7c5-f6e6-45a0-babb-1bdb364b70b0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# pdf document loader\n",
    "loader = PyPDFLoader(\n",
    "    \"./backend/tmc_tel_lab.pdf\"\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "8c62ac47-eb7d-4d8e-b620-2d9a61de25e8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "b43c96b9-4866-43de-8abe-6cacc65c4697",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Room to play\\nAt the Entrepreneurial Lab, we believe in the power of multidisciplinary collaboration and\\nthe freedom to explore. Here, diverse teams bringing together various skills to tackle the\\nmultifaceted challenges of today. It's where individual competencies unite to solve\\ncomplex problems, dri\""
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce950f21-f367-416e-a3ee-2e6e112969f9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### HandsOn --- Web Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dac2e60-8327-4fad-8817-55b090073e56",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> How can you use the WebBaseLoader to load the contents of the following website: \"https://www.themembercompany.com/nl/employeneurship\"?\n",
    "\n",
    "> How long is the page_content of the resulting document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "5778c31a-6138-4130-8865-31a08e82b9fb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# HandsOn: - Web Loader\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.themembercompany.com/nl/employeneurship\",)\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "8f04f1c4-ddf2-4c00-b3dd-8154e3ef994a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6840"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show character length page content\n",
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e55bc-acee-4378-9842-a20a504c5e9a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85118b9-cfed-4e89-9c02-75cd1be5ad1f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[Splitter](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbad834c-c2a5-4674-881a-663839b5565f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![assets/imgs/splitting_documents.png](assets/imgs/splitting_documents.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "e668d339-3951-4662-8387-c3d296646906",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=200, \n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=50, length_function=len)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca169f93-215a-4a99-bb28-b5b41d62aa08",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "46ca07fc-0036-4a60-9912-c7568d60e862",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "359faa46-81d6-4832-a193-5f2ad5009c47",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Room to play\\nAt the Entrepreneurial Lab, we believe in the power of multidisciplinary collaboration and\\nthe freedom to explore. Here, diverse teams bringing together various skills to tackle the\\nmultifaceted challenges of today. It's where individual competencies unite to solve\\ncomplex problems, driving innovative solutions through collective expertise.\\nThrough hands-on, experienced-based learning, we create an environment where\""
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "e70dfee8-75c6-4504-87c2-a46673488b8f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Room to play\\nAt the Entrepreneurial Lab, we believe in the power of multidisciplinary collaboration and\\nthe freedom to explore. Here, diverse teams bringing together various skills to tackle the\\nmultifaceted challenges of today. It's where individual competencies unite to solve\\ncomplex problems, driving innovative solutions through collective expertise.\\nThrough hands-on, experienced-based learning, we create an environment where\\nexperimentation is encouraged, failures are embraced as opportunities for growth, and\\nbreakthroughs are celebrated.\\nWhether it's pioneering technology or disruptive healthcare solutions, the Entrepreneurial\\nLab provides the space, resources, and collaborative spirit to turn your vision into a\\nsuccessful venture.\\nHow it works\\nSounds promising, doesn't it? But how exactly does the Entrepreneurial Lab operate?\\n> Our employeneurs work on their own innovation if they desire, but they do this\\nalongside their client project.\\n> TMC supports with a physical lab and possibly even with financial resources.\\n> The ownership of the innovation remains of our employeneurs; TMC has no interest in\\nit.\\nBUILDING THE FUTURE IN\\nThe Entrepreneurial Lab\\nThis is the place where you can let your technical dreams come true. If you\\nhave a groundbreaking idea for a new innovation, you can initiate your\\nproject and take it from concept to reality with the support of a vibrant\\ncommunity of like-minded innovators.\\x00 \\x00\""
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "c580505e-c75d-4749-8c52-b3171654542c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Room to play\\nAt the Entrepreneurial Lab, we believe in the power of multidisciplinary collaboration and\\nthe freedom to explore. Here, diverse teams bringing together various skills to tackle the\\nmultifaceted challenges of today. It's where individual competencies unite to solve\\ncomplex problems, driving innovative solutions through collective expertise.\\nThrough hands-on, experienced-based learning, we create an environment where\""
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "238b3a45-8093-4694-8697-6406c5b9c146",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"experimentation is encouraged, failures are embraced as opportunities for growth, and\\nbreakthroughs are celebrated.\\nWhether it's pioneering technology or disruptive healthcare solutions, the Entrepreneurial\\nLab provides the space, resources, and collaborative spirit to turn your vision into a\\nsuccessful venture.\\nHow it works\\nSounds promising, doesn't it? But how exactly does the Entrepreneurial Lab operate?\\n> Our employeneurs work on their own innovation if they desire, but they do this\""
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[1].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba267a-bc98-4020-bbdf-38f3e0a3d849",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f04fd74-829f-472c-a1bc-ec6521a0529f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[Text embedding models](https://python.langchain.com/docs/integrations/text_embedding/openai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615960ac-fe6c-4382-96d2-7daa65d9d358",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Text Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "14444a47-40d4-4d30-8990-396318d6ddf1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "OLLAMA_EMBEDDING_MODEL = \"all-minilm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "8d6378c5-2836-4a98-8d3d-e1a4aa4ab8e8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embedding = OllamaEmbeddings(model=OLLAMA_EMBEDDING_MODEL, base_url=OLLAMA_SERVER)\n",
    "query_result = embedding.embed_query(question)\n",
    "split_result = embedding.embed_query(splits[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "596cfd58-11c9-45d3-94df-52580ab49daa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b4f790c8-28ab-404a-8249-09b7b683ffb7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f717689a-9cbd-4259-9ef7-802b09f05440",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.050936587154865265,\n",
       " -0.0449187234044075,\n",
       " 0.02893143706023693,\n",
       " -0.017894087359309196]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_result[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe97626-8cf4-4944-bf85-839e38e07745",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0e35f-6861-4c5e-9301-04fd5408f8f8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[Cosine similarity](https://platform.openai.com/docs/guides/embeddings/frequently-asked-questions) is reccomended (1 indicates identical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "12668e52-bad0-4b0c-9c12-861e3c5b6c4d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2, print_output = False):\n",
    "    \n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    \n",
    "    similarity = dot_product / (norm_vec1 * norm_vec2)\n",
    "    \n",
    "    if print_output:\n",
    "        print(\"Cosine Similarity:\", similarity)\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "b0e464ae-6b39-4fa3-a758-5dc7e1cdc89a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.7672609792161257\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(query_result, split_result, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7379847f-a71f-4b39-aac8-22afbe0eb092",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### HandsOn --- Better Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd19f006-cc6f-47a1-a300-16786601cc64",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Write code to use the more sophisticated `mxbai-embed-large` instead of the `all-miniml` embedding model with the local Ollama instance. This enables better performance and more accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "39b29cf5-23ed-4c9c-8bc0-76e64e128cbf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "OLLAMA_EMBEDDING_MODEL = \"mxbai-embed-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "db83ad60-8290-4636-b426-fee4c8cde817",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embedding = OllamaEmbeddings(model=OLLAMA_EMBEDDING_MODEL, base_url=OLLAMA_SERVER)\n",
    "query_result = embedding.embed_query(question)\n",
    "split_result = embedding.embed_query(splits[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "588c2cf6-4e9c-46c7-89ab-5cfc4f9f13b3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.8523275629908142\n"
     ]
    }
   ],
   "source": [
    "similarity = cosine_similarity(query_result, split_result, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f9fdf0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### HandsOn --- Stroopwafel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d587e2c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> Similar to the `Japan - Germany` example from the `Introduction to LLMs` we will now calculate the distance between Netherlands and Germany in the vector space. This we can then use to understand what item in Germany corresponds to what the stroopwafel is in the Netherlands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "abc0e648",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "OLLAMA_EMBEDDING_MODEL = \"mxbai-embed-large\"\n",
    "embedding = OllamaEmbeddings(model=OLLAMA_EMBEDDING_MODEL, base_url=OLLAMA_SERVER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "2b8cc653",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Assuming embedding is some pre-trained embedding model with an embed_query method\n",
    "words = [\"Bratwurst\", \"Mercedes\", \"Schwarzwälder Kirschtorte\", \"Berliner\", \"Lebkuchen\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "a6e975ab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# getting vectors of tokens/ words\n",
    "stroopwafel_embedding = np.array(embedding.embed_query(\"Stroopwafel\"))\n",
    "netherlands_embedding = np.array(embedding.embed_query(\"Netherlands\"))\n",
    "germany_embedding = np.array(embedding.embed_query(\"Germany\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "25a9d2d4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# calculating the comparison vector\n",
    "comparison_embedding = stroopwafel_embedding - (netherlands_embedding - germany_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "0de488df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# initiating variables\n",
    "highest_similarity = -1\n",
    "closest_word = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "54dd1d9b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bratwurst\n",
      "Cosine Similarity: 0.7104238314729429\n",
      "\n",
      "Mercedes\n",
      "Cosine Similarity: 0.5495463777308662\n",
      "\n",
      "Schwarzwälder Kirschtorte\n",
      "Cosine Similarity: 0.6412197961550299\n",
      "\n",
      "Berliner\n",
      "Cosine Similarity: 0.7296874018682962\n",
      "\n",
      "Lebkuchen\n",
      "Cosine Similarity: 0.6988265639666382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running the loop\n",
    "for word in words:\n",
    "    \n",
    "    # embedding the query word\n",
    "    word_embedding = np.array(embedding.embed_query(word))\n",
    "\n",
    "    # generating output\n",
    "    print(word)\n",
    "    similarity = cosine_similarity(adjusted_stroopwafel_embedding, word_embedding, True)\n",
    "    print(\"\")\n",
    "\n",
    "    # capturing highest similarity\n",
    "    if similarity > highest_similarity:\n",
    "        highest_similarity = similarity\n",
    "        closest_word = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "fe6757bc-19f4-4e6f-ae27-4e1664a7f049",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word closest to 'stroopwafel' is 'Berliner' with a cosine similarity of 0.7296874018682962.\n"
     ]
    }
   ],
   "source": [
    "# final evaluation\n",
    "print(f\"The word closest to 'stroopwafel' is '{closest_word}' with a cosine similarity of {highest_similarity}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba890329-1411-4922-bd27-fe0490dd1208",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8459793e-838d-44fe-8c66-faf8fbe2ca5a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[Vectorstores](https://python.langchain.com/docs/integrations/vectorstores/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282072da-4993-4490-a263-41fe9799be47",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![assets/imgs/langchain_vectorstores_rag.png](assets/imgs/langchain_vectorstores_rag.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "fafdada1-4c4e-41f8-ad1a-33861aae3930",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(\n",
    "    collection_name=OLLAMA_EMBEDDING_MODEL,\n",
    "    documents=splits,\n",
    "    embedding=OllamaEmbeddings(model=OLLAMA_EMBEDDING_MODEL, base_url=OLLAMA_SERVER)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "3b36e8c0",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Room to playAt the Entrepreneurial Lab, we believe in the power of multidisciplinary collaboration and the freedom to explore.Here, diverse teams bringing together various skills to tackle the multifaceted challenges of today. It's whereindividual competencies unite to solve complex problems, driving innovative solutions through collectiveexpertise.Through hands-on, experienced-based learning, we create an environment where experimentation is encouraged,failures are embraced as opportunities for growth, and breakthroughs are celebrated.Whether it's pioneering technology or disruptive healthcare solutions, the Entrepreneurial Lab provides the space,resources, and collaborative spirit to turn your vision into a successful venture.How it worksSounds promising, doesn't it? But how exactly does the Entrepreneurial Lab operate?> Our employeneurs work on their own innovation if they desire, but they do this alongside their client project.> TMC supports with a physical lab and possibly even with financial resources.> The ownership of the innovation remains of our\", metadata={'page': 0, 'source': './backend/tmc_tel_lab.pdf'})]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing write code to look at what is in the chroma db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d736b8-d6e0-4da0-afaa-51b81046dfd3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "db96f877-60d3-4741-9846-e2903831583d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Room to playAt the Entrepreneurial Lab, we believe in the power of multidisciplinary collaboration and the freedom to explore.Here, diverse teams bringing together various skills to tackle the multifaceted challenges of today. It's whereindividual competencies unite to solve complex problems, driving innovative solutions through collectiveexpertise.Through hands-on, experienced-based learning, we create an environment where experimentation is encouraged,failures are embraced as opportunities for growth, and breakthroughs are celebrated.Whether it's pioneering technology or disruptive healthcare solutions, the Entrepreneurial Lab provides the space,resources, and collaborative spirit to turn your vision into a successful venture.How it worksSounds promising, doesn't it? But how exactly does the Entrepreneurial Lab operate?> Our employeneurs work on their own innovation if they desire, but they do this alongside their client project.> TMC supports with a physical lab and possibly even with financial resources.> The ownership of the innovation remains of our\""
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1f76bb9c-cafe-40c0-9bec-ff4651503492",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': 0, 'source': './backend/tmc_tel_lab.pdf'}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "c792e5dd-9940-402d-ac43-6b75504a819c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Room to playAt the Entrepreneurial Lab, we believe in the power of multidisciplinary collaboration and the freedom to explore.Here, diverse teams bringing together various skills to tackle the multifaceted challenges of today. It's whereindividual competencies unite to solve complex problems, driving innovative solutions through collectiveexpertise.Through hands-on, experienced-based learning, we create an environment where experimentation is encouraged,failures are embraced as opportunities for growth, and breakthroughs are celebrated.Whether it's pioneering technology or disruptive healthcare solutions, the Entrepreneurial Lab provides the space,resources, and collaborative spirit to turn your vision into a successful venture.How it worksSounds promising, doesn't it? But how exactly does the Entrepreneurial Lab operate?> Our employeneurs work on their own innovation if they desire, but they do this alongside their client project.> TMC supports with a physical lab and possibly even with financial resources.> The ownership of the innovation remains of our\n",
      "\n",
      "with a physical lab and possibly even with financial resources.> The ownership of the innovation remains of our employeneurs; TMC has no interest in it.> The first spin-offs have already been rolled out, that is what we call true employeneurship!Collaboration with our specialistsNext to our own projects, we offer support to external partiesseeking solutions for specific project challenges. Whether it’s atechnical issue or a strategic challenge, we offer a platform wherewe will dive into your project. By engaging with us, you gainaccess to a pool of top talent, our Employeneurs, who eagerlycontribute their expertise and creativity to address your needs.Let's unite our efforts and realize your project's goals by accessingthe combined expertise of our Entrepreneurial Lab's diversetalents and specialized knowledge.InternshipsIf you are an entrepreneurial student, excited to make an impact in a real-world project, the Entrepreneurial Labmight be just the\n",
      "\n",
      "to make an impact in a real-world project, the Entrepreneurial Labmight be just the place for you. We offer an environment where you can directly contribute by working on one ofthe projects, or conducting a research for one of them. Our experienced professionals are keen to guide you alongyour way as you help shape a beter tomorrow.\n",
      "\n",
      "▶\n",
      "Let's get in touch!Reach out for opportunities, collaborations, orquestions. We're here to connect.CONTACT US\n",
      "BUILDING THE FUTURE INThe EntrepreneurialLabThis is the place where you can let your technical dreamscome true. If you have a groundbreaking idea for a newinnovation, you can initiate your project and take it fromconcept to reality with the support of a vibrant community oflike-minded innovators.\n",
      "\n",
      "FOLLOW US:Our dedication lies in being a greatworkplace where our engineers,scientists, and digital experts canthrive. Together, we're not justshaping a company; we're buildingthe global home of employeneurs!CareersGraduate programsVIE ProgramCorporate vacanciesAll vacanciesService areasTechnology & EngineeringDigital & ITEnergy & RenewablesLife Sciences & PharmaDiscover TMCAbout usUpdatesFAQContact\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    print(split.page_content)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbf9e2e-329e-4c35-8f05-2dceea717daa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Combine Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4d17745b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'))])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "e4461264-5cac-479a-917c-9bf589826da4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# LLM\n",
    "llm = ChatOllama(model=OLLAMA_LARGE_LANGUAGE_MODEL, base_url=OLLAMA_SERVER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "55d6629f-18ec-4372-a557-b254fbb1dd2d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Chain\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e5985e-4131-446f-b4e5-baa57ec1929b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "94470770-8df4-4359-9504-ef6c8b3137ff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The TMC Entrepreneurial Lab is an initiative that fosters multidisciplinary collaboration by bringing together diverse teams with various skills to address complex challenges. It offers a space and resources for individuals to experiment, learn from failures, and celebrate breakthroughs in pioneering technology or healthcare solutions. Additionally, TMC supports employeneurs—employees who work as entrepreneurs—by allowing them to work on their own innovations alongside their client projects, providing both physical infrastructure and potentially financial support, while maintaining ownership of their innovation.'"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoking the RAG chain\n",
    "response = chain.invoke({\"context\":result,\"question\":question})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6c9497",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the `chain.invoke()` example above we used directly the result output of a similarity search of the vector database. Langchain has a better approach for this via retrievers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985a51dc-ea11-46b2-b8dc-272bfca63221",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "e03a2ff9-2343-4047-bb07-0a3cd4de73bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# here we create a retriever from the vectorstore which can perform similarity search and returns one document\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4a6e9-447d-499b-8fd4-5b73f5aa2040",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "ebe5ba3e-3af5-4d49-8e73-4531a6fb68d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \" The TMC Entrepreneurial Lab is not explicitly described in the provided context, but based on the tag and the use of 'tags' and 'search_kwargs', it appears to be an initiative or a project related to entrepreneurship, possibly utilizing technology like Chroma and vector embeddings from OllamaEmbeddings for various tasks such as search and data analysis. Without additional context, I can only infer that it is an entity focused on supporting entrepreneurial efforts, potentially through technological means.\",\n",
       " 'additional_kwargs': {},\n",
       " 'response_metadata': {'model': 'wizardlm2:7b',\n",
       "  'created_at': '2024-06-17T15:41:16.970708046Z',\n",
       "  'message': {'role': 'assistant', 'content': ''},\n",
       "  'done_reason': 'stop',\n",
       "  'done': True,\n",
       "  'total_duration': 35669502970,\n",
       "  'load_duration': 3057652251,\n",
       "  'prompt_eval_count': 180,\n",
       "  'prompt_eval_duration': 12327739000,\n",
       "  'eval_count': 103,\n",
       "  'eval_duration': 20238609000},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-570d2267-6ff3-4af5-9eef-106b7166f65c-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': None}"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "75d07a22-8234-40fa-973a-b5a84ec14023",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The TMC Entrepreneurial Lab is not explicitly described in the provided context, but based on the tag and the use of 'tags' and 'search_kwargs', it appears to be an initiative or a project related to entrepreneurship, possibly utilizing technology like Chroma and vector embeddings from OllamaEmbeddings for various tasks such as search and data analysis. Without additional context, I can only infer that it is an entity focused on supporting entrepreneurial efforts, potentially through technological means.\""
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with this retreiver the context (relevant split) is directry passed to the question addressing the LLM.\n",
    "response = chain.invoke({\"context\":retriever,\"question\":question})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "aa098889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" The TMC Entrepreneurial Lab is not explicitly described in the provided context, but based on the tag and the use of 'tags' and 'search_kwargs', it appears to be an initiative or a project related to entrepreneurship, possibly utilizing technology like Chroma and vector embeddings from OllamaEmbeddings for various tasks such as search and data analysis. Without additional context, I can only infer that it is an entity focused on supporting entrepreneurial efforts, potentially through technological means.\", response_metadata={'model': 'wizardlm2:7b', 'created_at': '2024-06-17T15:41:16.970708046Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 35669502970, 'load_duration': 3057652251, 'prompt_eval_count': 180, 'prompt_eval_duration': 12327739000, 'eval_count': 103, 'eval_duration': 20238609000}, id='run-570d2267-6ff3-4af5-9eef-106b7166f65c-0')"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748826de",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### HandsOn --- Answer not in Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087aad15",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> What happens if the answer is not in the splits of any retreived document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60696b2-067e-481d-a147-37032051e5f9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "response = chain.invoke({\"context\":retriever,\"question\":\"What is a large language model?\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03957484",
   "metadata": {},
   "source": [
    "#### Better Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "65770e2d-3d5e-4371-abc9-0aeca9646885",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt_hub_rag = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f53e5840-0a0f-4428-a4a4-6922800aff89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_hub_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e16118-a165-4808-adc7-d89d9d195706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3eaf19-5335-455f-a5fe-e54d6712f23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764f7f1-4cfb-4516-a7e6-f25a80e370fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "b9dd43a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" The TMC Entrepreneurial Lab is likely an initiative or program designed to support and foster entrepreneurship, possibly leveraging technology like Chroma for data storage and OllamaEmbeddings for natural language processing within a vector store context. The provided context seems to suggest that it might utilize advanced search capabilities with 'k': 1 for relevant information, indicating a focus on retrieving top-ranked results or data points. Without additional context, the exact nature of the lab and its specific activities remain uncertain.\", response_metadata={'model': 'wizardlm2:7b', 'created_at': '2024-06-17T15:34:32.13742427Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 25822861294, 'load_duration': 8436144, 'prompt_eval_count': 70, 'prompt_eval_duration': 5840493000, 'eval_count': 106, 'eval_duration': 19831949000}, id='run-972d617c-8f92-4671-bbca-f16cc559718e-0')"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "e4c0a8e0-cae9-4e6b-aca5-1851f2e737e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./backend/tmc_tel_lab.pdf'"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8208a8bc-c75f-4e8e-8601-680746cd6276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" A large language model like GPT-3 is an advanced AI system designed to understand and generate human-like text based on the input it receives. It is trained on vast amounts of data to perform a wide variety of natural language processing tasks, and it can assist with both technical issues and strategic challenges by providing insights or generating content relevant to those areas. The model itself, once trained, does not own the innovations it helps create; rather, the ownership typically remains with the creators or the entity that deployed the model. Large language models are used by various organizations, including TMC's Entrepreneurial Lab, to support employeneers and external parties in solving complex problems.\""
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the final output we might want to know in which document we can find the information of the similarity search.\n",
    "# This is handled by RunnablePassthrough() function which can add a \n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is a large language model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "abc499fa-ccea-436a-8aa8-08a8d4093c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant specialized in question-answering tasks. Use the given context to answer the question concisely. If the answer is not present in the context, clearly state that you don't know the answer and do not provide any further answer.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"You are an assistant specialized in question-answering tasks. Use the given context to answer the question concisely. If the answer is not present in the context, clearly state that you don't know the answer and do not provide any further answer.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "69cbc517-4587-4e9f-bec2-25c68692d348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' A large language model like me is a type of artificial intelligence that has been trained on vast amounts of text data to understand and generate human-like text based on the input it receives. It can perform a wide range of language tasks, including answering questions, translating languages, summarizing texts, and more. These models are \"large\" both in terms of their neural network size (number of parameters) and the diversity and volume of data they have been trained on to achieve a broad understanding of language and context.'"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is a large language model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe29a1-5527-419e-9f12-8a3061d12885",
   "metadata": {},
   "source": [
    "[RAG chains](https://python.langchain.com/docs/expression_language/get_started#rag-search-example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9fb95-db25-4a0d-ad21-2462e84c6206",
   "metadata": {},
   "source": [
    "## HandsOn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0ec39d-8bff-4c49-8582-268921e7854d",
   "metadata": {},
   "source": [
    "1. Rerun the overall app using a question which relates to the [website](https://www.themembercompany.com/nl/employeneurship). You first will have to load the website via WebBaseLoader.\n",
    "2. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3f197a-7dc4-42c5-a301-82634932b53e",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff57604-cb72-43c9-ba68-3131a2f0b282",
   "metadata": {},
   "source": [
    "Implementation of Simple Retrieval-Augmented Generation (RAG) from Scratch\n",
    "- **Ingestion Phase**:\n",
    "    - **Load**: Loading documents into the system.\n",
    "    - **Split**: Splitting documents into manageable chunks.\n",
    "    - **Embed**: Embedding document chunks into vector representations.\n",
    "    - **Store**: Storing the embedded documents in a vector store.\n",
    "- **Similarity Search**: Searching for relevant documents using embedded query.\n",
    "- **Combine Context**: Combining the retrieved document context with the query.\n",
    "- **Response Generation**: Generating the final response using a Large Language Model (LLM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eb00b8-cb17-4ae5-aef4-e0be6e89c070",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0a9c4-076a-4da9-bde9-f51cb30ee87a",
   "metadata": {},
   "source": [
    "There is plenty more to discover at [langchain's](https://github.com/langchain-ai) and many other websites! Especially check out: [YouTube](https://www.youtube.com/watch?v=sVcwVQRHIc8&ab_channel=freeCodeCamp.org) and [Github](https://github.com/langchain-ai/rag-from-scratch/tree/main). Here an overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33306e55-0ce9-4db7-ba48-5355311b5cd9",
   "metadata": {},
   "source": [
    "![assets/imgs/langchain_rag_overview.png](assets/imgs/langchain_rag_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f73c187-64ac-4b6e-a194-049282b5ca1b",
   "metadata": {},
   "source": [
    "## TMChampionship"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e3488-ccc1-400f-953c-fbc0fe6a9568",
   "metadata": {},
   "source": [
    "* TEL organises/-ed a project journey towards a shark tank like investor pitch in November\n",
    "* Milan and I - started TMChampionship project Prometheon.ai to build a sustainable manufacturing knowledge expert\n",
    "* TEL has many wonderful opportunities for you to try new things, learn, connect and especially grow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19445455-22ab-451a-a28c-e52c52112235",
   "metadata": {},
   "source": [
    "## Thank You"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc9dc9a-78d4-4088-87aa-17a972db96bf",
   "metadata": {},
   "source": [
    "- **Technical Support**: Milan and Raul\n",
    "- **Organisational Support**: Marlies, Wendy, and Varsha\n",
    "- **Motivational Support**: TMChampionship/ TEL/ Pepijn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed862a6c-8654-4e9c-beaa-a600d85b9496",
   "metadata": {},
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e65d82-c245-44d9-bae6-c9fadc326856",
   "metadata": {},
   "source": [
    "![assets/imgs/ai_workshop_tmc__feedback.png](assets/imgs/ai_workshop_tmc__feedback.png)\n",
    "\n",
    "https://forms.office.com/e/CwRvint3LY?origin=lprLink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fdf7bb-0415-4bec-b3b9-412f09e1eba6",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4398734-192f-4ee4-bf37-47bbc7aec96f",
   "metadata": {},
   "source": [
    "- **credits**: this notebook heavily borrows from langchain's [rag_from_scratch_1_to_4.ipynb](\"https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_1_to_4.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8a69a-5f46-4672-97ac-24ae362f04b5",
   "metadata": {},
   "source": [
    "* **GPT**: Generative Pre-trained Transformer, a type of language model developed by OpenAI that generates human-like text using transformer architecture.\n",
    "* **LLM**: Large Language Model, a machine learning model trained on vast amounts of text data to understand and generate human language.\n",
    "* **Transformer**: Deep learning model using attention mechanism for context understanding and parallel processing, introduced in the \"Attention is All You Need\" paper.\n",
    "* **Embedding Models**: Convert text to vector representations (e.g., BERT).\n",
    "* **Generation Models**: Generate text from prompts (e.g., GPT-3).\n",
    "* **Softmax Function**: Converts values to probabilities, used in classification models.\n",
    "* **Fine-Tune vs. Retrieval \"Augmented Generation**\n",
    "    * **Fine-Tuning an LLM**: Adapts model to specific tasks using labeled data.\n",
    "    * **RAG (Retrieval-Augmented Generation)**: Combines retrieval with generation for context-specific responses.\n",
    "* **Micro Timeline**\n",
    "    * **2017**: \"Attention is All You Need\" paper.\n",
    "    * **2018**: BERT, GPT-2\n",
    "    * **2020**: GPT-3.\n",
    "* **Quantization**: Reduces precision of model parameters.\n",
    "    * **Benefits**: Smaller size, faster inference, lower power consumption.\n",
    "    * **Types**: Static, Dynamic, Quantization-Aware Training.\n",
    "    * **Challenges**: Accuracy loss, hardware support needed.\n",
    "* **Not all LLMs are GPTs**: Other models include BERT, T5, XLNet, RoBERTa.\n",
    "* **Not all LLMs use transformers**: Other architectures include RNNs, CNNs, MoE, Memory-Augmented Networks."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
